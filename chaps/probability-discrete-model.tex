
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}

\title{Probability fundamentals}
\author{Gabriel Aguiar}
\date{August 2019}

\begin{document}

\maketitle

\section{Discrete model}

\begin{itemize}

\item We define as random variable a function $K: \Omega \rightarrow\ X$.

\item We define as discrete probability function $D: K \rightarrow\ [0, 1]$.

\item Discrete uniform distribution:

$P( x_{j} ) = \frac{1}{n}$

$x_{j} \in\{x_{1},..., x_{n}\}$

\item Geometric distribution:

$P(n) = (1 - p)^{n - 1} \; p$

$p$: Failure probability

\item Binomial distribution:

$P(k/n,p) = \binom{n}{k} \; p^{k} \; (1 - p)^{n - k}$

$k$: Occurrences; $n$: Attempts; $p$: Elementary probability

\item Poisson distribution (rare events):

This is the limit of Binomial distribution when $n \rightarrow \infty$:

$P(k/\lambda) = \frac{\lambda^{k}}{k!} \; e^{-\lambda}$

$k$: Occurrences; $\lambda$: Expected number of events

$p = \frac{\lambda}{n}$

$p$: Elementary probability

In the context of this distribution, it is convenient to define an entity called Expected value:

$\mathbb{E}(K) = \sum\limits_{k \geq 0} \; k \; P(k/\lambda) = \lambda$

$K$: Random variable

\item Hypergeometric distribution:

$P(k,n,n_{1},j) = \frac{1}{\binom{n}{j}} \; \binom{n_{1}}{k} \; \binom{n - n{1}}{j - k}$

$k$: Occurrences in the sample; $n$: Total size

$n_{1}$: Occurrences set size

\item Negative binomial distribution

$P(k/r,p) = \binom{r + k - 1}{k} \; p^{r} \; (1 - p)^{k}$

$k$: Number of failures; $r$: Number of hits; $p$: Hit probability

Or, with $n = r + k$ attempts for $r$ hits:

$P(n/r,p) = \binom{n - 1}{k} \; p^{r} \; (1 - p)^{n - r}$

\item Multinomial distribution:

$P(k_{1},...,k_{l}/p_{1},...,p_{l}) = \frac{n!}{k_{1}!...k_{l}!} \; p_{1}^{k_{1}}...p_{l}^{k_{l}}$

\item Zipf distribution:

$P(k/\alpha) = \frac{k^{-\alpha}}{A(\alpha)}$

$k \in \mathbb{N}$

\end{itemize}

\end{document}